<!-- markdownlint-disable first-line-h1 -->
<!-- markdownlint-disable html -->

<div align="center">
<h1>
  TransNormerLLM -- A Faster and Better LLM
</h1>
</div>

<p align="center">
ğŸ¤— <a href="https://huggingface.co/OpenNLPLab/" target="_blank">Hugging Face</a> â€¢ ğŸ’¬ <a href="https://discord.gg/W4Vr7AKW" target="_blank">Discord</a> â€¢ ğŸ’¬ <a href="./images/contact_me_qr.png" target="_blank">å¾®ä¿¡</a> 
</p>
<div align="center">

[![license](https://img.shields.io/github/license/modelscope/modelscope.svg)](https://github.com/OpenNLPLab/TransNormerLLM/blob/main/LICENSE)
<h4 align="center">
    <p>
        <a href="https://github.com/OpenNLPLab/TransNormerLLM/blob/main/README.md">English</a> |
        <b>ä¸­æ–‡</b> 
    <p>
</h4>
</div>

------
- [å…¥é—¨ç®€ä»‹](#å…¥é—¨ç®€ä»‹)
- [å¼€æºæ¨¡å‹](#å¼€æºæ¨¡å‹)
- [è¯„æµ‹ç»“æœ](#è¯„æµ‹ç»“æœ)
  - [é€šç”¨é¢†åŸŸ](#é€šç”¨é¢†åŸŸ)
    - [æ¨¡å‹ç»“æœ](#æ¨¡å‹ç»“æœ)
- [æ¨ç†éƒ¨ç½²](#æ¨ç†éƒ¨ç½²)
  - [Dependency Installation](#dependency-installation)
  - [Notice](#notice)
  - [Python æ¨ç†ä»£ç ](#python-æ¨ç†ä»£ç )
    - [åŸºç¡€æ¨¡å‹æ¨ç†æ¼”ç¤º](#åŸºç¡€æ¨¡å‹æ¨ç†æ¼”ç¤º)
- [å¾®è°ƒæ¨¡å‹](#å¾®è°ƒæ¨¡å‹)
  - [ä¾èµ–å®‰è£…](#ä¾èµ–å®‰è£…)
  - [è®­ç»ƒ](#è®­ç»ƒ)
- [ç¤¾åŒºç”Ÿæ€](#ç¤¾åŒºç”Ÿæ€)
- [è®¸å¯å£°æ˜](#è®¸å¯å£°æ˜)
  - [å£°æ˜](#å£°æ˜)
  - [åè®®](#åè®®)
  - [è‡´è°¢](#è‡´è°¢)
  - [å¼•ç”¨](#å¼•ç”¨)

# å…¥é—¨ç®€ä»‹

æˆ‘ä»¬æ­£åœ¨é‡æ–°å®šä¹‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚è¯¥ä»£ç ä»“åº“æ˜¯[TransNormerLLM](https://arxiv.org/pdf/2307.14995.pdf)çš„å®˜æ–¹å®ç°ã€‚ æˆ‘ä»¬çš„ TransNormerLLM å¼€æ”¾æƒç°åœ¨å¯ä¾›ä¸ªäººã€åˆ›ä½œè€…ã€ç ”ç©¶äººå‘˜å’Œå„ç§è§„æ¨¡çš„ä¼ä¸šä½¿ç”¨ï¼Œä»¥ä¾¿ä»–ä»¬èƒ½å¤Ÿè´Ÿè´£ä»»åœ°å®éªŒã€åˆ›æ–°å’Œæ‰©å±•ä»–ä»¬çš„æƒ³æ³•ã€‚

æˆ‘ä»¬å¼€æ”¾çš„ç‰ˆæœ¬åŒ…å« TransNormerLLM æ¨¡å‹å®ç°ã€å¼€æºæƒé‡å’Œç›‘ç£å¾®è°ƒ (SFT) çš„èµ·å§‹ä»£ç ã€‚ æˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•åŠ è½½ [TransNormerLLM](https://arxiv.org/pdf/2307.14995.pdf) æ¨¡å‹ã€è¿è¡Œ SFT å¹¶å¯¹å…¶è¿›è¡Œæ¨ç†çš„ç¤ºä¾‹ã€‚

- TransNormerLLM æ˜¯ç¬¬ä¸€ä¸ªåŸºäºçº¿æ€§æ³¨æ„åŠ›çš„ LLMï¼Œåœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡æ–¹é¢å‡ä¼˜äºä¼ ç»Ÿçš„åŸºäº softmax æ³¨æ„åŠ›çš„æ¨¡å‹ã€‚ å®ƒæ˜¯åœ¨å…·æœ‰ **1.4 ä¸‡äº¿** çš„é«˜è´¨é‡tokenè¯­æ–™åº“ä¸Šè¿›è¡Œè®­ç»ƒçš„ã€‚
- TransNormerLLM ä»ä¹‹å‰çš„çº¿æ€§æ³¨æ„åŠ›æ¶æ„ TransNormer æ¼”å˜è€Œæ¥ï¼Œè¿›è¡Œäº†ä¸€ç³»åˆ—çš„ä¼˜åŒ–ï¼ŒåŒ…æ‹¬ LRPE ä½ç½®åµŒå…¥ã€é—ªç”µæ³¨æ„åŠ›åŠ é€Ÿã€æ–°çš„é—¨æ§å’Œæ ‡å‡†åŒ–æœºåˆ¶ã€‚
- TransNormerLLM åœ¨å¤šä¸ªå¹¿å—è®¤å¯çš„ä¸­æ–‡ã€è‹±æ–‡ä»¥åŠå¤šè¯­è¨€é€šç”¨å’Œç‰¹å®šé¢†åŸŸåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†åŒç±»è§„æ¨¡çš„éå¸¸æœ‰ç«äº‰æ€§çš„æ€§èƒ½ã€‚
- æ­¤ç‰ˆæœ¬åŒ…æ‹¬å…·æœ‰ **385M**ã€**1B** å’Œ **7B** å‚æ•°çš„ **Base** ç‰ˆæœ¬ã€‚
- æ‰€æœ‰ç‰ˆæœ¬å‡å®Œå…¨å¼€æ”¾ç»™å­¦æœ¯ç ”ç©¶ã€‚ å¼€å‘è€…åªéœ€é€šè¿‡ç”µå­é‚®ä»¶ç”³è¯·å¹¶è·å¾—å®˜æ–¹å•†ä¸šè®¸å¯å³å¯å…è´¹å•†ä¸šä½¿ç”¨ã€‚
- æ¬²äº†è§£æ›´å¤šä¿¡æ¯ï¼Œæ¬¢è¿é˜…è¯»æˆ‘ä»¬çš„å­¦æœ¯è®ºæ–‡[TransNormerLLM](https://arxiv.org/pdf/2307.14995.pdf)ã€‚

![](./images/TransNormerLLM-arch.png)

# å¼€æºæ¨¡å‹

å…·ä½“å‘å¸ƒç‰ˆæœ¬åŠä¸‹è½½é“¾æ¥å¦‚ä¸‹ï¼š

|         | åŸºç¡€æ¨¡å‹  | 
|:-------:|:-----------:|
| 385M      | ğŸ¤— [TransNormerLLM-385M](https://huggingface.co/OpenNLPLab/TransNormerLLM-385M) | 
| 1B     | ğŸ¤— [TransNormerLLM-1B](https://huggingface.co/OpenNLPLab/TransNormerLLM-1B) |
| 7B (release soon)     | ğŸ¤— [TransNormerLLM-7B](https://huggingface.co/OpenNLPLab/TransNormerLLM-7B) | 

# è¯„æµ‹ç»“æœ

ä¸ºäº†éªŒè¯ TransNormerLLMï¼Œæˆ‘ä»¬åœ¨ Commonsense Reasoning Taskã€MMLUã€CMMLU å’Œ C-Eval ä¸Šæµ‹è¯•äº† 385Mã€1B å’Œ 7B æ¨¡å‹ã€‚ ä¸ºäº†è¿›è¡Œæ¯”è¾ƒï¼Œæˆ‘ä»¬é€‰æ‹©äº†å‡ ä¸ªå¼€æºæ¨¡å‹ä½œä¸ºæ¯”è¾ƒï¼ŒåŒ…æ‹¬åŸºäº Transformer çš„æ¨¡å‹ï¼Œå¦‚ OPTã€Pythiaã€BLOOMã€GPT-Neoã€GPT-Jã€MPTã€Falconã€LLaMA1/2ã€OpenLLAMA v1/v2ã€Baichuan 1/ 2ã€ChatGLM 1/2ï¼Œä»¥åŠéTransformeræ¨¡å‹RWKVã€‚ å¯ä»¥çœ‹å‡ºï¼Œä¸è¿™äº›æ¨¡å‹ç›¸æ¯”ï¼ŒTransNormerLLMä»ç„¶å…·æœ‰å¾ˆå¼ºçš„ç«äº‰åŠ›ã€‚

**å¸¸è¯†æ¨ç†** æˆ‘ä»¬æŠ¥å‘Š BoolQã€PIQAã€SIQAã€
HellaSwagã€WinoGrandeã€ARC ç®€å•å’ŒæŒ‘æˆ˜ã€OpenBookQA åŠå…¶å¹³å‡å€¼ã€‚ æˆ‘ä»¬ä½¿ç”¨ LM-Eval-Harness æŠ¥å‘Šæ‰€æœ‰åŸºå‡†æµ‹è¯•çš„0-shotç»“æœã€‚
ä¸ç°æœ‰æœ€å…ˆè¿›çš„å¤§è¯­è¨€æ¨¡å‹ç›¸æ¯”ï¼Œæˆ‘ä»¬æ‰€æœ‰çš„æ¨¡å‹éƒ½å–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„è¡¨ç°ï¼Œå±•ç¤ºäº†ç†è§£å’Œåº”ç”¨å¸¸è¯†æ¨ç†çš„å“è¶Šèƒ½åŠ›ã€‚

**æ±‡æ€»åŸºå‡†**
æˆ‘ä»¬æŠ¥å‘Š MMLUã€CMMLUã€C-Eval çš„æ€»ä½“ç»“æœã€‚ä½¿ç”¨å®˜æ–¹è„šæœ¬æ¥è¯„ä¼° MMLUã€CMMLU å’Œ C-Evalï¼Œæ‰€æœ‰è¯„ä¼°ç»“æœå‡é‡‡ç”¨ 5-shotç»“æœã€‚ ä¸ä¸šç•Œé¡¶çº§çš„å¼€æºæ¨¡å‹ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨è‹±æ–‡å’Œä¸­æ–‡åŸºå‡†æµ‹è¯•ä¸­éƒ½è¡¨ç°å‡ºäº†ç›¸åŒ¹é…çš„æ€§èƒ½ã€‚


## é€šç”¨é¢†åŸŸ

åœ¨é€šç”¨é¢†åŸŸï¼Œæˆ‘ä»¬å¯¹ä»¥ä¸‹æ•°æ®é›†è¿›è¡Œäº† 5-shot æµ‹è¯•ï¼š
- [C-Eval](https://cevalbenchmark.com/index.html#home)æ˜¯ä¸€ä¸ªç»¼åˆæ€§çš„ä¸­æ–‡åŸºç¡€æ¨¡å‹è¯„ä¼°æ•°æ®é›†ï¼Œæ¶µç›–52ä¸ªå­¦ç§‘å’Œå››ä¸ªéš¾åº¦çº§åˆ«ã€‚ æˆ‘ä»¬ä½¿ç”¨è¯¥æ•°æ®é›†çš„å¼€å‘é›†ä½œä¸ºå°æ ·æœ¬å­¦ä¹ çš„æ¥æºï¼Œå¹¶åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæµ‹è¯•ã€‚ æˆ‘ä»¬çš„è¯„ä¼°æ–¹æ³•éµå¾ª [LM-Evaluation-Harness](https://github.com/EleutherAI/lm-evaluation-harness)ã€‚
- [MMLU](https://arxiv.org/abs/2009.03300)æ˜¯ä¸€ä¸ªè‹±è¯­è¯„ä¼°æ•°æ®é›†ï¼ŒåŒ…å«57ä¸ªä»»åŠ¡ï¼Œæ¶µç›–å°å­¦æ•°å­¦ã€ç¾å›½å†å²ã€è®¡ç®—æœºç§‘å­¦ã€æ³•å¾‹ç­‰ï¼Œéš¾åº¦ä»é«˜ä¸­æ°´å¹³åˆ°ä¸“å®¶æ°´å¹³ ã€‚ å®ƒæ˜¯ä¸»æµçš„LLMè¯„ä¼°æ•°æ®é›†ã€‚ æˆ‘ä»¬ä½¿ç”¨å…¶[å®˜æ–¹](https://github.com/hendrycks/test)è¯„ä¼°æ–¹æ³•ã€‚
- [CMMLU](https://github.com/haonan-li/CMMLU)æ˜¯ä¸€ä¸ªæ¶µç›–67ä¸ªä¸»é¢˜çš„ç»¼åˆä¸­æ–‡è¯„ä¼°åŸºå‡†ï¼Œä¸“é—¨ç”¨äºè¯„ä¼°è¯­è¨€æ¨¡å‹åœ¨ä¸­æ–‡èƒŒæ™¯ä¸‹çš„çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ã€‚ æˆ‘ä»¬é‡‡ç”¨äº†å…¶[å®˜æ–¹](https://github.com/haonan-li/CMMLU)è¯„ä¼°æ–¹æ³•ã€‚


### æ¨¡å‹ç»“æœ

**å¸¸è¯†æ¨ç†å’Œé€šç”¨é¢†åŸŸæ€§èƒ½æ¯”è¾ƒã€‚** ä¸ºäº†å…¬å¹³æ¯”è¾ƒï¼Œæˆ‘ä»¬æŠ¥å‘Šäº†æˆ‘ä»¬ä½¿ç”¨å…¶å‘å¸ƒçš„æ¨¡å‹é‡ç°çš„ç«äº‰æ–¹æ³•çš„ç»“æœã€‚  PSï¼šå‚æ•°å¤§å°ï¼ˆåäº¿ï¼‰ã€‚ Tï¼šTokensï¼ˆä¸‡äº¿ï¼‰ã€‚ HSï¼šHellaSwagã€‚ WGï¼šWinoGrandeã€‚

| Model       | PS   | T    | BoolQ          | PIQA           | HS             | WG             | ARC-e          | ARC-c          | OBQA           | MMLU           | CMMLU          | C-Eval         |
|-------------|------|------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|----------------|
| OPT         | 0.35 | 0.30 | 57.74          | 64.58          | 36.69          | 52.49          | 44.02          | 23.89          | 28.20          | 26.02          | 25.34          | 25.71          |
| Pythia      | 0.40 | 0.30 | 60.40          | 67.08          | 40.52          | 53.59          | 51.81          | 24.15          | 29.40          | 25.99          | 25.16          | 24.81          |
| BLOOM       | 0.56 | 0.35 | 55.14          | 64.09          | 36.97          | 52.80          | 47.35          | 23.98          | 28.20          | 24.80          | 25.35          | 27.14          |
| RWKV        | 0.43 | -    | -              | 67.52   | 40.90 | 51.14 | 52.86 | 25.17 | 32.40 | 24.85          | -              | -              |
| **Ours**        | 0.39 | 1.0  | 62.14          | 66.70          | 46.27          | 54.46          | 55.43          | 27.99          | 32.40          | 25.90          | 25.05          | 25.24          |
| GPT-Neo     | 1.3  | 0.3  | 61.99          | 71.11          | 48.93          | 54.93          | 56.19          | 25.85          | 33.60          | 24.82          | 26.03          | 23.94          |
| OPT         | 1.3  | 0.3  | 57.77          | 71.71          | 53.70          | 59.35          | 57.24          | 29.69          | 33.20          | 24.96          | 24.97          | 25.32          |
| Pythia      | 1.4  | 0.3  | 60.73          | 70.67          | 47.18          | 53.51          | 56.99          | 26.88          | 31.40          | 26.55          | 25.13          | 24.25          |
| BLOOM       | 1.1  | 0.35 | 59.08          | 67.14          | 42.98          | 54.93          | 51.47          | 25.68          | 29.40          | 27.30          | 25.09          | 26.50          |
| RWKV        | 1.5  | -    | -              | 72.36 | 52.48 | 54.62 | 60.48 | 29.44 | 34.00 | 25.77          | -              | -              |
| Falcon      | 1.0  | 0.35 | 61.38          | 75.14          | 61.50          | 60.30          | 63.38          | 32.17          | 35.60          | 25.28          | 24.88          | 25.66          |
| **Ours**        | 1.0  | 1.2  | 63.27          | 72.09          | 56.49          | 60.38          | 63.68          | 35.24          | 36.60          | 27.10          | 25.88          | 26.01          |
| GPT-J       | 6.9  | 0.3  | 65.44          | 75.41          | 66.25          | 64.09          | 66.92          | 36.60          | 38.20          | 25.40          | 26.47          | 23.39          |
| OPT         | 6.7  | 0.3  | 66.18          | 76.22          | 67.21          | 65.19          | 65.66          | 34.64          | 37.20          | 24.57          | 25.36          | 25.32          |
| Pythia      | 6.9  | 0.3  | 63.46          | 75.14          | 63.92          | 60.77          | 67.34          | 35.41          | 37.00          | 24.64          | 25.56          | 26.40          |
| BLOOM       | 7.1  | 0.35 | 62.91          | 72.69          | 62.33          | 64.01          | 65.11          | 33.45          | 35.80          | 26.25          | 24.97          | 24.25          |
| RWKV        | 7.4  | -    | -              | 76.06 | 65.51 | 61.01 | 67.80 | 37.46 | 40.20 | 24.96          | -              | -              |
| MPT         | 6.9  | 1.0  | 73.88          | 79.43          | 76.25          | 68.27          | 74.79          | 41.72          | 42.20          | 30.80          | 25.99          | 24.06          |
| Falcon      | 7.2  | 1.5  | 73.73          | 79.38          | 76.3           | 67.17          | 74.62          | 43.60          | 43.80          | 27.79          | 25.73          | 22.92          |
| Baichuan1   | 7.0  | 1.2  | 70.09          | 76.01          | 70.06          | 64.09          | 71.72          | 40.53          | 38.20          | 42.30 | 44.43 | 42.80 |
| Baichuan2   | 7.0  | 2.6  | 72.72          | 76.50          | 72.17          | 68.35          | 75.17          | 42.32          | 39.60          | 54.16 | 57.07 | 54.00 |
| ChatGLM1    | 6.7  | 1.0  | 74.74          | 68.88          | 45.57          | 52.25          | 48.78          | 31.66          | 36.80          | 40.63 | 37.48          | 40.23 |
| ChatGLM2    | 7.1  | 1.4  | 77.65          | 69.37          | 50.51          | 57.62          | 59.13          | 34.30          | 37.00          | 45.46 | 48.80          | 52.55 |
| OpenLLaMAv1 | 6.7  | 1.0  | 70.43          | 75.68          | 69.23          | 66.69          | 71.17          | 38.57          | 39.00          | 30.49          | 25.40          | 26.09          |
| OpenLLaMAv2 | 6.7  | 1.0  | 72.20          | 78.84          | 74.51          | 65.67          | 72.39          | 41.30          | 41.00          | 41.29          | 29.58          | 30.01          |
| LLaMA1      | 6.7  | 1.0  | 76.50 | 79.80 | 76.10 | 70.10 | 72.80 | 47.60 | 57.20 | 35.10 | 25.62          | 25.72          |
| LLaMA2      | 6.7  | 2.0  | 77.68 | 78.07 | 76.02 | 68.98 | 76.30 | 46.33 | 44.20 | 45.30 | 32.96          | 33.20          |
| **Ours**        | 6.8  | 1.4  | 75.87          | 80.09          | 75.21          | 66.06          | 75.42          | 44.40          | 63.40          | 43.10          | 47.99          | 43.18          |


# æ¨ç†éƒ¨ç½²

æ¨ç†æ‰€éœ€çš„æ¨¡å‹æƒé‡ã€æºä»£ç å’Œé…ç½®å·²åœ¨ Hugging Face ä¸Šå‘å¸ƒã€‚ ä¸‹è½½é“¾æ¥å¯ä»¥åœ¨æœ¬æ–‡æ¡£å¼€å¤´çš„[è¡¨æ ¼](#å¼€æºæ¨¡å‹)ä¸­æ‰¾åˆ°ã€‚ ä¸‹é¢ï¼Œæˆ‘ä»¬ä»¥ TransNormerLLM-1B ä¸ºä¾‹æ¼”ç¤ºå„ç§æ¨ç†æ–¹æ³•ã€‚ ç¨‹åºä¼šè‡ªåŠ¨ä»Hugging Faceä¸‹è½½æ‰€éœ€çš„èµ„æºã€‚
## Dependency Installation

```shell
pip install -r requirements.txt
```

## Notice
If you encounter errors related to Triton, please set the following environment variables:
```
export use_triton=False
```

## Python æ¨ç†ä»£ç 

### åŸºç¡€æ¨¡å‹æ¨ç†æ¼”ç¤º

```python
>>> from transformers import AutoModelForCausalLM, AutoTokenizer
>>> tokenizer = AutoTokenizer.from_pretrained("OpenNLPLab/TransNormerLLM-1B", trust_remote_code=True)
>>> model = AutoModelForCausalLM.from_pretrained("OpenNLPLab/TransNormerLLM-1B", device_map="auto", trust_remote_code=True)
```

> åœ¨ä¸Šé¢çš„ä»£ç ç‰‡æ®µä¸­ï¼Œæ¨¡å‹åŠ è½½æŒ‡å®š`device_map='auto'`ï¼Œå®ƒå°†ä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„GPUã€‚ å¦‚æœéœ€è¦æŒ‡å®šè¦ä½¿ç”¨çš„è®¾å¤‡ï¼Œå¯ä»¥é€šè¿‡ç±»ä¼¼äºâ€œexport CUDA_VISIBLE_DEVICES=0,1â€ï¼ˆä½¿ç”¨0å’Œ1æ˜¾å¡ï¼‰çš„æ–¹å¼è¿›è¡Œæ§åˆ¶ã€‚

# å¾®è°ƒæ¨¡å‹

## ä¾èµ–å®‰è£…

```shell
git clone https://github.com/OpenNLPLab/TransNormerLLM.git
cd TransNormerLLM/fine-tune
pip install -r requirements.txt
```
- è¦ä½¿ç”¨LoRAç­‰è½»é‡çº§å¾®è°ƒæ–¹æ³•ï¼Œæ‚¨å¿…é¡»å¦å¤–å®‰è£…[peft](https://github.com/huggingface/peft)ã€‚

## è®­ç»ƒ

ä¸‹é¢ï¼Œæˆ‘ä»¬æä¾›äº†ä½¿ç”¨ ZeRO-3 åœ¨å•å°æœºå™¨ä¸Šå¾®è°ƒ TransNormerLLM-7B-Base çš„ç¤ºä¾‹ã€‚

è®­ç»ƒæ•°æ®ï¼š`alpaca_data.json`ã€‚ æ­¤ç¤ºä¾‹æ•°æ®å–è‡ª [alpaca_data.json](https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/main/alpaca_data.json)ï¼ŒåŒ…å« 52,002 ä¸ªæ¡ç›®çš„é€‰æ‹©ï¼Œå¹¶å·²é‡æ–°æ ¼å¼åŒ–ã€‚ ä¸»è¦ç›®çš„æ˜¯æ¼”ç¤ºå¦‚ä½•SFTæˆ‘ä»¬çš„æ¨¡å‹ï¼Œä¸ä¿è¯æœ‰æ•ˆæ€§ã€‚

```shell
torchrun \
    --nproc_per_node=8 \
    train.py \
    --model_name_or_path OpenNLPLab/TransNormerLLM-1B \
    --data_path ./alpaca_data.json \
    --output_dir output \
    --num_train_epochs 1 \
    --per_device_train_batch_size 2 \
    --per_device_eval_batch_size 1 \
    --gradient_accumulation_steps 1 \
    --bf16 true \
    --adam_beta1 0.9 \
    --adam_beta2 0.95 \
    --evaluation_strategy "no" \
    --save_strategy "steps" \
    --save_steps 5000 \
    --save_total_limit 30 \
    --learning_rate 1e-4 \
    --weight_decay 0.1 \
    --warmup_ratio 0.1 \
    --lr_scheduler_type "cosine" \
    --deepspeed 'configs/zero3.json' \
    --logging_steps 1 \
    --dataloader_num_workers 24 \
    --ddp_find_unused_parameters false \
    --tf32 true \
```

# ç¤¾åŒºç”Ÿæ€

**ğŸ“¢ğŸ“¢ğŸ“¢æˆ‘ä»¬å°†ä¸æ–­æ›´æ–°è¿™é‡Œç¤¾åŒºå’Œç”Ÿæ€ç³»ç»Ÿå¯¹ TransNormerLLM çš„æ”¯æŒğŸ˜€ğŸ˜€ğŸ˜€**
- [nanoTransnormer](https://github.com/Doraemonzzz/nanoTransNormer)

# è®¸å¯å£°æ˜

## å£°æ˜


æˆ‘ä»¬ç‰¹æ­¤å£°æ˜ï¼Œæˆ‘ä»¬çš„å›¢é˜Ÿæ²¡æœ‰å¼€å‘è¿‡ä»»ä½•åŸºäº TransNormerLLM æ¨¡å‹çš„åº”ç”¨ç¨‹åºï¼Œä¹Ÿæ²¡æœ‰åœ¨ iOSã€Androidã€Web æˆ–ä»»ä½•å…¶ä»–å¹³å°ä¸Šå¼€å‘è¿‡ã€‚ æˆ‘ä»¬å¼ºçƒˆå‘¼åæ‰€æœ‰ç”¨æˆ·ä¸è¦åˆ©ç”¨TransNormerLLMæ¨¡å‹è¿›è¡Œä»»ä½•å±å®³å›½å®¶/ç¤¾ä¼šå®‰å…¨æˆ–è¿æ³•çš„æ´»åŠ¨ã€‚ æ­¤å¤–ï¼Œæˆ‘ä»¬è¦æ±‚ç”¨æˆ·ä¸è¦å°† TransNormerLLM æ¨¡å‹ç”¨äºæœªç»è¿‡é€‚å½“å®‰å…¨å®¡æŸ¥å’Œå¤‡æ¡ˆçš„äº’è”ç½‘æœåŠ¡ã€‚ æˆ‘ä»¬å¸Œæœ›æ‰€æœ‰ç”¨æˆ·éƒ½èƒ½éµå®ˆè¿™ä¸€åŸåˆ™ï¼Œç¡®ä¿æŠ€æœ¯çš„å‘å±•åœ¨è§„èŒƒã€åˆæ³•çš„ç¯å¢ƒä¸­è¿›è¡Œã€‚

æˆ‘ä»¬å·²å°½åŠ›ç¡®ä¿æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ•°æ®çš„åˆè§„æ€§ã€‚ ç„¶è€Œï¼Œå°½ç®¡æˆ‘ä»¬ä»˜å‡ºäº†å·¨å¤§çš„åŠªåŠ›ï¼Œç”±äºæ¨¡å‹å’Œæ•°æ®çš„å¤æ‚æ€§ï¼Œä»ç„¶å¯èƒ½ä¼šå‡ºç°ä¸€äº›ä¸å¯é¢„è§çš„é—®é¢˜ã€‚ å› æ­¤ï¼Œå¦‚æœå› ä½¿ç”¨TransNormerLLMå¼€æºæ¨¡å‹è€Œå‡ºç°ä»»ä½•é—®é¢˜ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºæ•°æ®å®‰å…¨é—®é¢˜ã€èˆ†æƒ…é£é™©ï¼Œæˆ–æ¨¡å‹è¢«è¯¯å¯¼ã€æ»¥ç”¨ã€ä¼ æ’­æˆ–ä¸å½“åˆ©ç”¨å¸¦æ¥çš„ä»»ä½•é£é™©å’Œé—®é¢˜ï¼Œ æˆ‘ä»¬å°†ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚

## åè®®

TransNormerLLM æ¨¡å‹çš„ç¤¾åŒºä½¿ç”¨éœ€è¦éµå®ˆ [Apache 2.0](https://github.com/OpenNLPLab/TransNormerLLM/blob/main/LICENSE) å’Œ [TransNormerLLM æ¨¡å‹ç¤¾åŒºè®¸å¯è¯](https://huggingface.co/OpenNLPLab/TransNormerLLM-7B-Base/resolve/main/TransNormerLLM%202%E6%A8%A1%E5%9E%8B%E7%A4%BE%E5%8C%BA%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE.pdf)ã€‚  TransNormerLLM æ¨¡å‹æ”¯æŒå•†ä¸šç”¨é€”ã€‚ å¦‚æœæ‚¨è®¡åˆ’å°†TransNormerLLMæ¨¡å‹æˆ–å…¶è¡ç”Ÿå“ç”¨äºå•†ä¸šç›®çš„ï¼Œè¯·ç¡®ä¿æ‚¨çš„å®ä½“æ»¡è¶³ä»¥ä¸‹æ¡ä»¶ï¼š

   1. æ‚¨æˆ–æ‚¨å…³è”å…¬å¸çš„æœåŠ¡æˆ–äº§å“çš„æ—¥æ´»è·ƒç”¨æˆ·ï¼ˆDAUï¼‰ä½äº100ä¸‡ã€‚
   2. æ‚¨æˆ–æ‚¨çš„å…³è”å…¬å¸éƒ½ä¸æ˜¯è½¯ä»¶æœåŠ¡æä¾›å•†æˆ–äº‘æœåŠ¡æä¾›å•†ã€‚
   3. æœªç» TransNormerLLM è®¸å¯ï¼Œæ‚¨æˆ–æ‚¨çš„å…³è”å…¬å¸ä¸å¯èƒ½å°†ç»™äºˆæ‚¨çš„å•†ä¸šè®¸å¯æˆäºˆæˆ–é‡æ–°æˆæƒç»™å…¶ä»–ç¬¬ä¸‰æ–¹ã€‚

æ»¡è¶³ä¸Šè¿°æ¡ä»¶åï¼Œæ‚¨éœ€è¦é€šè¿‡ä»¥ä¸‹è”ç³»é‚®ç®±æäº¤TransNormerLLMæ¨¡å‹ç¤¾åŒºè®¸å¯åè®®æ‰€éœ€çš„ç”³è¯·ææ–™ï¼šopennlplab@gmail.comã€‚ ä¸€æ—¦è·å¾—æ‰¹å‡†ï¼ŒTransNormerLLM å°†ç‰¹æ­¤æˆäºˆæ‚¨éæ’ä»–æ€§ã€å…¨çƒæ€§ã€ä¸å¯è½¬è®©ã€ä¸å¯å†è®¸å¯ã€å¯æ’¤é”€çš„å•†ä¸šç‰ˆæƒè®¸å¯ã€‚

## è‡´è°¢
æˆ‘ä»¬çš„é¡¹ç›®åŸºäºå¦‚ä¸‹å¼€æºé¡¹ç›®è¿›è¡Œå¼€å‘:
- [Baichuan](https://github.com/baichuan-inc/Baichuan-7B)ç”¨äºtokenizeréƒ¨åˆ†ã€‚
- [metaseq](https://github.com/facebookresearch/metaseq)ç”¨äºè®­ç»ƒéƒ¨åˆ†ã€‚
- [lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness)ç”¨äºæµ‹è¯„éƒ¨åˆ†ã€‚


## å¼•ç”¨

å¦‚æœæ‚¨æƒ³å¼•ç”¨æˆ‘ä»¬çš„å·¥ä½œï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹å‚è€ƒæ–‡çŒ®ï¼š
```
@article{qin2023scaling,
  title={Scaling transnormer to 175 billion parameters},
  author={Qin, Zhen and Li, Dong and Sun, Weigao and Sun, Weixuan and Shen, Xuyang and Han, Xiaodong and Wei, Yunshen and Lv, Baohong and Yuan, Fei and Luo, Xiao and others},
  journal={arXiv preprint arXiv:2307.14995},
  year={2023}
}
```
